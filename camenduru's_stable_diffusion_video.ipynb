{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/camenduru/notebooks/blob/main/camenduru's_stable_diffusion_video.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "!git clone https://github.com/rokibulislaam/colab-ffmpeg-cuda.git\n",
        "!cp -r ./colab-ffmpeg-cuda/bin/. /usr/bin/\n",
        "\n",
        "!pip install -qq git+https://github.com/huggingface/diffusers.git\n",
        "!pip install -qq transformers ftfy\n",
        "\n",
        "import torch, os, gc, requests, subprocess\n",
        "from diffusers import StableDiffusionPipeline\n",
        "from torch import autocast\n",
        "from IPython.display import clear_output, HTML\n",
        "from base64 import b64encode\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "F1WTBlIF4SyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "is_tile = False #@param {type: 'boolean'}\n",
        "if(is_tile):\n",
        "\tdef patch_conv(cls):\n",
        "\t\tinit = cls.__init__\n",
        "\t\tdef __init__(self, *args, **kwargs):\n",
        "\t\t\treturn init(self, *args, **kwargs, padding_mode='circular')\n",
        "\t\tcls.__init__ = __init__\n",
        "\tpatch_conv(torch.nn.Conv2d)\n",
        " \n",
        "pipe = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\", revision=\"fp16\", torch_dtype=torch.float16, use_auth_token=\"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\").to(\"cuda\")\n",
        "pipe.safety_checker = lambda images, **kwargs: [images, [False] * len(images)]\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "Xi6SOT9mZ6-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token = '' #@param {type: 'string'}\n",
        "header = {\"authorization\": f\"Bot {token}\"}\n",
        "channel_id = 0 #@param {type: 'integer'}\n",
        "by = 'camenduru' #@param {type: 'string'}\n",
        "\n",
        "root_folder = '/content/gdrive/MyDrive/AI/StableDiffusion' #@param {type: 'string'}\n",
        "image_folder = '000' #@param {type: 'string'}\n",
        "if os.path.exists(f\"{root_folder}/{image_folder}\") == False:\n",
        "  os.mkdir(f\"{root_folder}/{image_folder}\")\n",
        "name = max([int(f[:f.index('.')]) for f in os.listdir(f\"{root_folder}/{image_folder}\")], default=0)\n",
        "\n",
        "from PIL.PngImagePlugin import PngInfo\n",
        "metadata = PngInfo()\n",
        " \n",
        "height = 448 #@param {type: 'integer'}\n",
        "width = 832 #@param {type: 'integer'}\n",
        "\n",
        "def generate(prompt, name):\n",
        "  metadata.add_text(\"Prompt\", f\"{prompt}\")\n",
        "  metadata.add_text(\"by\", f\"{by}\")\n",
        "  gc.collect()\n",
        "  torch.cuda.empty_cache()\n",
        "  with autocast(\"cuda\"):\n",
        "    image = pipe(prompt, height=height, width=width, num_inference_steps=50, eta=0.0, guidance_scale=7.5)[\"sample\"][0]\n",
        "  image.save(f\"{root_folder}/{image_folder}/{name:04}.png\", pnginfo=metadata)\n",
        "  files = {f\"{image_folder}_{name:04}.png\" : open(f\"{root_folder}/{image_folder}/{name:04}.png\", \"rb\").read()}\n",
        "  payload = {\"content\":f\"{prompt}\"}\n",
        "  r = requests.post(f\"https://discord.com/api/v9/channels/{channel_id}/messages\", data=payload, headers=header, files=files).text\n",
        "  clear_output()\n",
        "\n",
        "max_files = 100 #@param {type: 'integer'}\n",
        "is_from_prompts_txt = False #@param {type: 'boolean'}\n",
        "prompts_txt = 'prompts.txt' #@param {type: 'string'}\n",
        "if(is_from_prompts_txt):\n",
        "  while name < max_files:\n",
        "    with open(f'{prompts_txt}', \"r\") as file:\n",
        "      prompts = file.readlines()\n",
        "    for prompt in prompts:\n",
        "      name += 1\n",
        "      generate(prompt, name)\n",
        "else:\n",
        "  prompt = '' #@param {type: 'string'}\n",
        "  while name < max_files:\n",
        "    name += 1\n",
        "    generate(prompt, name)\n",
        "\n",
        "video_folder = 'videos' #@param {type: 'string'}\n",
        "if os.path.exists(f\"{root_folder}/{video_folder}\") == False:\n",
        "  os.mkdir(f\"{root_folder}/{video_folder}\")\n",
        "\n",
        "fps = 1/3\n",
        "scale = '854:480' #@param {type: 'string'}\n",
        "cmd = ['ffmpeg','-y','-vcodec','png','-r',f'{fps}','-hwaccel','cuda','-hwaccel_output_format','cuda','-i',f'{root_folder}/{image_folder}/%04d.png','-vf',f'scale={scale}','-c:v','h264_nvenc','-b:v','100M',f'{root_folder}/{video_folder}/{image_folder}.mp4']\n",
        "process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "stdout, stderr = process.communicate()\n",
        "if process.returncode != 0:\n",
        "  print(stderr)\n",
        "  raise RuntimeError(stderr)\n",
        "\n",
        "mp4 = open(f'{root_folder}/{video_folder}/{image_folder}.mp4','rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(f'<video width={width} controls><source src=\"{data_url}\" type=\"video/mp4\"></video>')"
      ],
      "metadata": {
        "id": "7tOGrS5lA6-D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
