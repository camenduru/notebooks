{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/camenduru/notebooks/blob/main/camenduru's_stable_diffusion_discord.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F1WTBlIF4SyA"
      },
      "outputs": [],
      "source": [
        "!pip install -q torch==1.13.1+cu116 torchvision==0.14.1+cu116 torchaudio==0.13.1 torchtext==0.14.1 torchdata==0.5.1 --extra-index-url https://download.pytorch.org/whl/cu116 -U\n",
        "!pip install -qq git+https://github.com/huggingface/diffusers.git\n",
        "!pip install -qq transformers ftfy\n",
        "\n",
        "import torch, os, gc, requests, random\n",
        "from diffusers import StableDiffusionPipeline\n",
        "from torch import autocast\n",
        "from IPython.display import clear_output\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MBkgalN4dHV9"
      },
      "outputs": [],
      "source": [
        "is_tile = False #@param {type: 'boolean'}\n",
        "if(is_tile):\n",
        "\tdef patch_conv(cls):\n",
        "\t\tinit = cls.__init__\n",
        "\t\tdef __init__(self, *args, **kwargs):\n",
        "\t\t\treturn init(self, *args, **kwargs, padding_mode='circular')\n",
        "\t\tcls.__init__ = __init__\n",
        "\tpatch_conv(torch.nn.Conv2d)\n",
        " \n",
        "pipe = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\", revision=\"fp16\", torch_dtype=torch.float16, use_auth_token=\"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\").to(\"cuda\")\n",
        "pipe.safety_checker = lambda images, clip_input: (images, False)\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7tOGrS5lA6-D"
      },
      "outputs": [],
      "source": [
        "token = '' #@param {type: 'string'}\n",
        "header = {\"authorization\": f\"Bot {token}\"}\n",
        "by = 'camenduru' #@param {type: 'string'}\n",
        "\n",
        "from PIL.PngImagePlugin import PngInfo\n",
        "metadata = PngInfo()\n",
        " \n",
        "height = 512 #@param {type: 'integer'}\n",
        "width = 512 #@param {type: 'integer'}\n",
        "\n",
        "def generate(prompt):\n",
        "  metadata.add_text(\"Prompt\", f\"{prompt}\")\n",
        "  metadata.add_text(\"by\", f\"{by}\")\n",
        "  gc.collect()\n",
        "  torch.cuda.empty_cache()\n",
        "  with autocast(\"cuda\"):\n",
        "    image = pipe(prompt, height=height, width=width, num_inference_steps=50, eta=0.0, guidance_scale=7.5)[\"sample\"][0]\n",
        "  random_name = random.randint(0,10000000000)\n",
        "  image.save(f\"{random_name}.png\", pnginfo=metadata)\n",
        "  files = {f\"{random_name}.png\" : open(f\"{random_name}.png\", \"rb\").read()}\n",
        "  payload = {\"content\":f\"{prompt}\"}\n",
        "  channel_id = 0 #@param {type: 'integer'}\n",
        "  r = requests.post(f\"https://discord.com/api/v9/channels/{channel_id}/messages\", data=payload, headers=header, files=files).text\n",
        "  os.remove(f\"{random_name}.png\")\n",
        "  clear_output()\n",
        "\n",
        "is_from_prompts_txt = True #@param {type: 'boolean'}\n",
        "prompts_txt = 'prompts.txt' #@param {type: 'string'}\n",
        "if(is_from_prompts_txt):\n",
        "  while True:\n",
        "    with open(f'{prompts_txt}', \"r\") as file:\n",
        "      prompts = file.readlines()\n",
        "    for prompt in prompts:\n",
        "      generate(prompt)\n",
        "else:\n",
        "  while True:\n",
        "    prompt = '' #@param {type: 'string'}\n",
        "    generate(prompt)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
