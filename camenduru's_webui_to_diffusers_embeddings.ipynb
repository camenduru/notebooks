{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/camenduru/notebooks/blob/main/camenduru's_webui_to_diffusers_embeddings.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oRljt9Kfhh5r"
      },
      "outputs": [],
      "source": [
        "!pip install -q diffusers transformers ftfy accelerate\n",
        "!pip install -q https://github.com/camenduru/stable-diffusion-webui-colab/releases/download/0.0.15/xformers-0.0.15.dev0+189828c.d20221207-cp38-cp38-linux_x86_64.whl\n",
        "\n",
        "import os, torch\n",
        "from PIL import Image\n",
        "from diffusers import StableDiffusionPipeline\n",
        "from transformers import CLIPTextModel, CLIPTokenizer\n",
        "\n",
        "model_path = \"lilpotat/a3\"\n",
        "tokenizer = CLIPTokenizer.from_pretrained(model_path, subfolder=\"tokenizer\")\n",
        "text_encoder = CLIPTextModel.from_pretrained(model_path, subfolder=\"text_encoder\")\n",
        "\n",
        "def load_learned_embed_in_clip(learned_embeds_path, text_encoder, tokenizer, token=None, type=0):\n",
        "  # filename, file_extension = os.path.splitext(learned_embeds_path)\n",
        "  loaded_learned_embeds = torch.load(learned_embeds_path, map_location=\"cpu\")\n",
        "  # if (file_extension == \".pt\"):\n",
        "  if(type == 0):\n",
        "    trained_token = list(loaded_learned_embeds.keys())[0]\n",
        "    embeds = loaded_learned_embeds[trained_token]\n",
        "  elif(type == 1):\n",
        "    string_to_token = loaded_learned_embeds['string_to_token']\n",
        "    string_to_param = loaded_learned_embeds['string_to_param']\n",
        "    trained_token = list(string_to_token.keys())[0]\n",
        "    embeds = string_to_param[trained_token]\n",
        "    embeds = embeds.detach()\n",
        "    embeds = embeds[1]\n",
        "  elif(type == 2):\n",
        "    embeds = loaded_learned_embeds[0]\n",
        "  dtype = text_encoder.get_input_embeddings().weight.dtype\n",
        "  embeds.to(dtype)\n",
        "  token = token if token is not None else trained_token\n",
        "  num_added_tokens = tokenizer.add_tokens(token)\n",
        "  if num_added_tokens == 0:\n",
        "    raise ValueError(f\"The tokenizer already contains the token {token}.\")\n",
        "  text_encoder.resize_token_embeddings(len(tokenizer))\n",
        "  token_id = tokenizer.convert_tokens_to_ids(token)\n",
        "  text_encoder.get_input_embeddings().weight.data[token_id] = embeds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WulKgO4aSK1L"
      },
      "outputs": [],
      "source": [
        "!wget https://huggingface.co/datasets/Nerfgun3/bad_prompt/resolve/main/bad_prompt_version2.pt\n",
        "!wget https://github.com/MushroomFleet/djz-Aesthetic-Embeddings/raw/main/djz-CyberCityV0.pt\n",
        "!wget https://gitgud.io/viper1/stable-diffusion-embeddings/-/raw/master/embeddings/botan-50000.pt\n",
        "!wget https://raw.githubusercontent.com/hlky/sd-embeddings/main/anya/anya.pt\n",
        "!wget https://huggingface.co/datasets/Nerfgun3/bad_prompt/resolve/main/bad_prompt.pt\n",
        "!wget https://huggingface.co/sd-concepts-library/midjourney-style/resolve/main/learned_embeds.bin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vHP8f5gWMnlc"
      },
      "outputs": [],
      "source": [
        "# load_learned_embed_in_clip(\"/content/bad_prompt.pt\", text_encoder, tokenizer, \"bad_prompt\", type=1)\n",
        "# load_learned_embed_in_clip(\"/content/djz-CyberCityV0.pt\", text_encoder, tokenizer, \"CyberCityV0\", type=2)\n",
        "# load_learned_embed_in_clip(\"/content/botan-50000.pt\", text_encoder, tokenizer, \"botan-50000\", type=2)\n",
        "load_learned_embed_in_clip(\"/content/learned_embeds.bin\", text_encoder, tokenizer, type=0)\n",
        "# load_learned_embed_in_clip(\"/content/4tnght.pt\", text_encoder, tokenizer, \"<4tNGHT>\", type=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SUu2dkv5DOe3"
      },
      "outputs": [],
      "source": [
        "pipe = StableDiffusionPipeline.from_pretrained(model_path, text_encoder=text_encoder, tokenizer=tokenizer, safety_checker=None).to(\"cuda\")\n",
        "pipe.enable_xformers_memory_efficient_attention()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wj-Bz_5vhdcO"
      },
      "outputs": [],
      "source": [
        "# with torch.autocast(\"cuda\"):\n",
        "#   image = pipe(\"<midjourney-style> house\").images[0]\n",
        "# display(image)\n",
        "\n",
        "# with torch.autocast(\"cuda\"):\n",
        "#   image = pipe(\"<4tNGHT>\").images[0]\n",
        "# display(image)\n",
        "\n",
        "# with torch.autocast(\"cuda\"):\n",
        "#   image = pipe(\"girl waiving\", negative_prompt=\"bad_prompt\").images[0]\n",
        "# display(image)\n",
        " \n",
        "generator = torch.cuda.manual_seed(10)\n",
        "with torch.autocast(\"cuda\"):\n",
        "  image = pipe(\"cute girl waving to camera <midjourney-style>\", negative_prompt=\"\", generator=generator).images[0]\n",
        "real_seed = torch.cuda.initial_seed()\n",
        "display(image)\n",
        "print(real_seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjtrVr7ZECFn",
        "outputId": "3f7b250d-41b5-4413-c79f-5a068242ac3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([768])\n"
          ]
        }
      ],
      "source": [
        "def test_learned_embed_in_clip(learned_embeds_path):\n",
        "  loaded_learned_embeds = torch.load(learned_embeds_path, map_location=\"cpu\")\n",
        "  trained_token = list(loaded_learned_embeds.keys())[0]\n",
        "  embeds = loaded_learned_embeds[trained_token]\n",
        "  # print(loaded_learned_embeds)\n",
        "  print(embeds.shape)\n",
        "\n",
        "# test_learned_embed_in_clip(\"/content/anya.pt\")\n",
        "# test_learned_embed_in_clip(\"/content/botan-50000.pt\")\n",
        "# test_learned_embed_in_clip(\"/content/djz-CyberCityV0.pt\")\n",
        "test_learned_embed_in_clip(\"/content/learned_embeds.bin\")\n",
        "# test_learned_embed_in_clip(\"/content/bad_prompt_version2.pt\")\n",
        "# test_learned_embed_in_clip(\"/content/4tnght.pt\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
