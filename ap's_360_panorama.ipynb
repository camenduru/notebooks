{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/camenduru/notebooks/blob/main/ap's_360_panorama.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 1\n",
    "!pip install diffusers==0.19.1 transformers accelerate streamlit streamlit_pannellum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step2\n",
    "from diffusers import StableDiffusionLDM3DPipeline\n",
    "from PIL import Image\n",
    "from typing import Optional\n",
    "from torch import Tensor\n",
    "from torch.nn import functional as F\n",
    "from torch.nn import Conv2d\n",
    "from torch.nn.modules.utils import _pair\n",
    "\n",
    "# Load the pipeline\n",
    "pipe = StableDiffusionLDM3DPipeline.from_pretrained(\"Intel/ldm3d-pano\")\n",
    "pipe.to(\"cuda\")\n",
    "\n",
    "# Function to override _conv_forward method\n",
    "def asymmetricConv2DConvForward(self, input: Tensor, weight: Tensor, bias: Optional[Tensor]):\n",
    "    paddingX = (self._reversed_padding_repeated_twice[0], self._reversed_padding_repeated_twice[1], 0, 0)\n",
    "    paddingY = (0, 0, self._reversed_padding_repeated_twice[2], self._reversed_padding_repeated_twice[3])\n",
    "    working = F.pad(input, paddingX, mode='circular')\n",
    "    working = F.pad(working, paddingY, mode='constant')\n",
    "    return F.conv2d(working, weight, bias, self.stride, _pair(0), self.dilation, self.groups)\n",
    "\n",
    "# Patch the Conv2d layers\n",
    "targets = [pipe.vae, pipe.text_encoder, pipe.unet]\n",
    "for target in targets:\n",
    "    for module in target.modules():\n",
    "        if isinstance(module, Conv2d):\n",
    "            module._conv_forward = asymmetricConv2DConvForward.__get__(module, Conv2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prompt and filename base\n",
    "prompt = \"The living room\"\n",
    "name = \"jungle_pano\"\n",
    "\n",
    "# Generate the images\n",
    "output = pipe(prompt, width=1024, height=512, guidance_scale=7.0, num_inference_steps=50)\n",
    "\n",
    "# Extract the RGB and depth images\n",
    "rgb_image, depth_image = output.rgb, output.depth\n",
    "\n",
    "# Save images to files\n",
    "rgb_image[0].save(name+\"_ldm3d_rgb.jpg\")\n",
    "depth_image[0].save(name+\"_ldd3d_depth.png\")\n",
    "\n",
    "# Display images\n",
    "rgb_image[0].show()\n",
    "depth_image[0].show()\n",
    "\n",
    "#step3\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "# File names from the saved images\n",
    "rgb_filename = name + \"_ldm3d_rgb.jpg\"\n",
    "\n",
    "# Open the saved images\n",
    "rgb_saved_image = Image.open(rgb_filename)\n",
    "\n",
    "# Display the images\n",
    "display(rgb_saved_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upscale step 1\n",
    "!pip install -q realesrgan==0.3.0\n",
    "!wget https://huggingface.co/camenduru/sd-t2i-360panoimage/resolve/main/RealESRGAN_x2plus.pth?download=true -O /content/RealESRGAN_x2plus.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upscale step 2\n",
    "from PIL import Image\n",
    "rgb_saved_image = Image.open('/content/jungle_pano_ldm3d_rgb.jpg')\n",
    "\n",
    "from basicsr.archs.rrdbnet_arch import RRDBNet\n",
    "from realesrgan import RealESRGANer\n",
    "\n",
    "sr_model = RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64, num_block=23, num_grow_ch=32,scale=2)\n",
    "upsampler = RealESRGANer(scale=2, model_path='/content/RealESRGAN_x2plus.pth', dni_weight=None, model=sr_model, tile=384, tile_pad=20, pre_pad=20, half=False, device='cuda',)\n",
    "\n",
    "import numpy as np\n",
    "output_img = rgb_saved_image.resize((1024 * 2, 512 * 2))\n",
    "w = output_img.size[0]\n",
    "blend_extend = 10\n",
    "outscale = 2\n",
    "output_img = np.array(output_img)\n",
    "output_img = np.concatenate([output_img, output_img[:, :blend_extend, :]], axis=1)\n",
    "output_img, _ = upsampler.enhance(output_img, outscale=outscale)\n",
    "output_img = Image.fromarray(output_img[:, :w * outscale, :])\n",
    "output_img"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
