{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/camenduru/notebooks/blob/main/camenduru's_replace_vae.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub pytorch_lightning"
      ],
      "metadata": {
        "id": "-yAt44bHJ2FA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# kohya_ss さん、記事ありがとうございます。❤ ❤ https://note.com/kohya_ss/n/nf5893a2e719c \n",
        "\n",
        "import torch\n",
        "\n",
        "def merge_vae(ckpt, vae, output):\n",
        "  print(f\"load checkpoint: {ckpt}\")\n",
        "  model = torch.load(ckpt, map_location=\"cpu\")\n",
        "  if \"state_dict\" in model:\n",
        "    sd = model[\"state_dict\"]\n",
        "  else:\n",
        "    sd = model\n",
        "\n",
        "  full_model = False\n",
        "\n",
        "  print(f\"load VAE: {vae}\")\n",
        "  vae_model = torch.load(vae, map_location=\"cpu\")\n",
        "  vae_sd = vae_model['state_dict']\n",
        "\n",
        "  for vae_key in vae_sd:\n",
        "    if vae_key.startswith(\"first_stage_model.\"):\n",
        "      full_model = True\n",
        "      break\n",
        "\n",
        "  for vae_key in vae_sd:\n",
        "    sd_key = vae_key\n",
        "    if full_model:\n",
        "      if not sd_key.startswith(\"first_stage_model.\"):\n",
        "        continue\n",
        "    else:\n",
        "      if sd_key not in sd:\n",
        "        sd_key = \"first_stage_model.\" + sd_key\n",
        "    if sd_key not in sd:\n",
        "      print(f\"key not exists in model: {vae_key}\")\n",
        "      continue\n",
        "    sd[sd_key] = vae_sd[vae_key]\n",
        "\n",
        "  print(f\"saving checkpoint to: {output}\")\n",
        "  torch.save(model, output)\n",
        "\n",
        "!wget https://huggingface.co/andite/anything-v4.0/resolve/main/anything-v4.5-pruned.ckpt\n",
        "!wget https://huggingface.co/andite/anything-v4.0/resolve/main/anything-v4.0.vae.pt\n",
        "!mkdir /content/swapped\n",
        "merge_vae(\"/content/anything-v4.5-pruned.ckpt\", \"/content/anything-v4.0.vae.pt\", \"/content/swapped/anything-v4.5-vae-swapped.ckpt\")"
      ],
      "metadata": {
        "id": "M_2AkptCHdoN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from huggingface_hub import create_repo, upload_folder\n",
        "\n",
        "hf_token=\"\"\n",
        "repo_id = \"ckpt/anything-v4.5-vae-swapped\"\n",
        "path_in_repo = \"\"\n",
        "create_repo(repo_id, private=True, token=hf_token)\n",
        "upload_folder(folder_path=\"/content/swapped\", path_in_repo=path_in_repo, repo_id=repo_id, commit_message=f\"anything-v4.5-vae-swapped\", token=hf_token)"
      ],
      "metadata": {
        "id": "OWB0IWajJB1r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
