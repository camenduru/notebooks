{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/camenduru/notebooks/blob/main/camenduru's_discord_diffusers.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wR009yNE2Gko"
      },
      "outputs": [],
      "source": [
        "!pip install -q torch==1.13.1+cu116 torchvision==0.14.1+cu116 torchaudio==0.13.1 torchtext==0.14.1 torchdata==0.5.1 --extra-index-url https://download.pytorch.org/whl/cu116 -U\n",
        "!pip install -q https://github.com/camenduru/stable-diffusion-webui-colab/releases/download/0.0.15/xformers-0.0.15.dev0+189828c.d20221207-cp38-cp38-linux_x86_64.whl\n",
        "!pip install -U -q  git+https://github.com/camenduru/diffusers transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvUpT9bGvwdN"
      },
      "outputs": [],
      "source": [
        "import torch, os, gc, requests, json\n",
        "from diffusers import StableDiffusionPipeline\n",
        "from PIL.PngImagePlugin import PngInfo\n",
        "\n",
        "metadata = PngInfo()\n",
        "\n",
        "def closestNumber(n, m):\n",
        "    q = int(n / m)\n",
        "    n1 = m * q\n",
        "    if (n * m) > 0:\n",
        "        n2 = m * (q + 1)\n",
        "    else:\n",
        "        n2 = m * (q - 1)\n",
        "    if abs(n - n1) < abs(n - n2):\n",
        "        return n1\n",
        "    return n2\n",
        "\n",
        "is_tile = False #@param {type: 'boolean'}\n",
        "if is_tile:\n",
        "    def patch_conv(cls):\n",
        "        init = cls.__init__\n",
        "        def __init__(self, *args, **kwargs):\n",
        "            return init(self, *args, **kwargs, padding_mode=\"circular\")\n",
        "        cls.__init__ = __init__\n",
        "    patch_conv(torch.nn.Conv2d)\n",
        "\n",
        "model_hash = \"none\" #@param {type: 'string'}\n",
        "max_files = 500 #@param {type: 'string'}\n",
        "root_folder = \"images\" #@param {type: 'string'}\n",
        "model_name = \"hakurei/waifu-diffusion\" #@param [\"nitrosocke/mo-di-diffusion\", \"hakurei/waifu-diffusion\"] {allow-input: true}\n",
        "pipe = StableDiffusionPipeline.from_pretrained(model_name, safety_checker=None).to(\"cuda\")\n",
        "\n",
        "if os.path.exists(f\"{root_folder}\") == False:\n",
        "    os.mkdir(f\"{root_folder}\")\n",
        "image_folder = max([int(f) for f in os.listdir(f\"{root_folder}\")], default=0)\n",
        "if os.path.exists(f\"{root_folder}/{image_folder:04}\") == False:\n",
        "    os.mkdir(f\"{root_folder}/{image_folder:04}\")\n",
        "name = max([int(f[: f.index(\".\")]) for f in os.listdir(f\"{root_folder}/{image_folder:04}\")],default=0,)\n",
        "\n",
        "def generate(discord_token, discord_channel_id, by, num_inference_steps, guidance_scale, sampler, width, height, prompt, image_folder, name):\n",
        "    width = closestNumber(width, 8)\n",
        "    height = closestNumber(height, 8)\n",
        "    metadata.add_text(\"Prompt\", f\"{prompt}\")\n",
        "    metadata.add_text(\"by\", f\"{by}\")\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    image = pipe([prompt], height=height, width=width, num_inference_steps=num_inference_steps, guidance_scale=guidance_scale).images[0]\n",
        "    initial_seed = torch.cuda.initial_seed()\n",
        "    image.save(f\"{root_folder}/{image_folder:04}/{name:04}.png\", pnginfo=metadata)\n",
        "    files = {f\"{image_folder:04}_{name:04}.png\": open(f\"{root_folder}/{image_folder:04}/{name:04}.png\", \"rb\").read()}\n",
        "    payload = {\"content\": f\"{prompt}\\nSteps: {num_inference_steps}, Sampler: {sampler}, CFG scale: {guidance_scale}, Seed: {initial_seed}, Size: {width}x{height}, Model hash: {model_hash}, Model name: {model_name}\"}\n",
        "    requests.post(f\"https://discord.com/api/v9/channels/{discord_channel_id}/messages\", data=payload, headers={\"authorization\": f\"Bot {discord_token}\"}, files=files)\n",
        "\n",
        "while True:\n",
        "    if name < max_files:\n",
        "        with open(\"prompts.json\", \"r\") as file:\n",
        "            prompts = file.readlines()\n",
        "        for prompt in prompts:\n",
        "            d = json.loads(prompt)\n",
        "            name += 1\n",
        "            generate(d[\"discord_token\"], d[\"discord_channel_id\"], d[\"by\"], d[\"num_inference_steps\"], d[\"guidance_scale\"], d[\"sampler\"], d[\"width\"], d[\"height\"], d[\"prompt\"], image_folder, name)\n",
        "    else:\n",
        "        image_folder += 1\n",
        "        if os.path.exists(f\"{root_folder}/{image_folder:04}\") == False:\n",
        "            os.mkdir(f\"{root_folder}/{image_folder:04}\")\n",
        "        name = 0"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
