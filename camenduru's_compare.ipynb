{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/camenduru/notebooks/blob/main/camenduru's_compare.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rbyb3ZDDyMoE"
      },
      "outputs": [],
      "source": [
        "!pip install -q torch==1.13.1+cu116 torchvision==0.14.1+cu116 torchaudio==0.13.1 torchtext==0.14.1 torchdata==0.5.1 --extra-index-url https://download.pytorch.org/whl/cu116 -U\n",
        "!pip install safetensors pytorch_lightning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pe33yPgLyZHZ"
      },
      "outputs": [],
      "source": [
        "# from https://huggingface.co/JosephusCheung/ASimilarityCalculatior\n",
        "\n",
        "from safetensors.torch import load_file\n",
        "import sys\n",
        "import torch\n",
        "from pathlib import Path\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def cal_cross_attn(to_q, to_k, to_v, rand_input):\n",
        "    hidden_dim, embed_dim = to_q.shape\n",
        "    attn_to_q = nn.Linear(hidden_dim, embed_dim, bias=False)\n",
        "    attn_to_k = nn.Linear(hidden_dim, embed_dim, bias=False)\n",
        "    attn_to_v = nn.Linear(hidden_dim, embed_dim, bias=False)\n",
        "    attn_to_q.load_state_dict({\"weight\": to_q})\n",
        "    attn_to_k.load_state_dict({\"weight\": to_k})\n",
        "    attn_to_v.load_state_dict({\"weight\": to_v})\n",
        "    \n",
        "    return torch.einsum(\n",
        "        \"ik, jk -> ik\", \n",
        "        F.softmax(torch.einsum(\"ij, kj -> ik\", attn_to_q(rand_input), attn_to_k(rand_input)), dim=-1),\n",
        "        attn_to_v(rand_input)\n",
        "    )\n",
        "\n",
        "def model_hash(filename):\n",
        "    try:\n",
        "        with open(filename, \"rb\") as file:\n",
        "            import hashlib\n",
        "            m = hashlib.sha256()\n",
        "\n",
        "            file.seek(0x100000)\n",
        "            m.update(file.read(0x10000))\n",
        "            return m.hexdigest()[0:8]\n",
        "    except FileNotFoundError:\n",
        "        return 'NOFILE'\n",
        "        \n",
        "def load_model(path):\n",
        "    if path.suffix == \".safetensors\":\n",
        "        return load_file(path, device=\"cpu\")\n",
        "    else:\n",
        "        ckpt = torch.load(path, map_location=\"cpu\")\n",
        "        return ckpt[\"state_dict\"] if \"state_dict\" in ckpt else ckpt\n",
        "        \n",
        "def eval(model, n, input):\n",
        "    qk = f\"model.diffusion_model.output_blocks.{n}.1.transformer_blocks.0.attn1.to_q.weight\"\n",
        "    uk = f\"model.diffusion_model.output_blocks.{n}.1.transformer_blocks.0.attn1.to_k.weight\"\n",
        "    vk = f\"model.diffusion_model.output_blocks.{n}.1.transformer_blocks.0.attn1.to_v.weight\"\n",
        "    atoq, atok, atov = model[qk], model[uk], model[vk]\n",
        "\n",
        "    attn = cal_cross_attn(atoq, atok, atov, input)\n",
        "    return attn\n",
        "\n",
        "def main():\n",
        "    file1 = Path(sys.argv[1])\n",
        "    files = sys.argv[2:]\n",
        "    \n",
        "    seed = 114514\n",
        "    torch.manual_seed(seed)\n",
        "    print(f\"seed: {seed}\") \n",
        "    \n",
        "    model_a = load_model(file1)\n",
        "    \n",
        "    print()\n",
        "    print(f\"base: {file1.name} [{model_hash(file1)}]\")\n",
        "    print()\n",
        "\n",
        "    map_attn_a = {}\n",
        "    map_rand_input = {}\n",
        "    for n in range(3, 11):\n",
        "        hidden_dim, embed_dim = model_a[f\"model.diffusion_model.output_blocks.{n}.1.transformer_blocks.0.attn1.to_q.weight\"].shape\n",
        "        rand_input = torch.randn([embed_dim, hidden_dim])\n",
        "\n",
        "        map_attn_a[n] = eval(model_a, n, rand_input)\n",
        "        map_rand_input[n] = rand_input\n",
        "        \n",
        "    del model_a\n",
        "     \n",
        "    for file2 in files:\n",
        "        file2 = Path(file2)\n",
        "        model_b = load_model(file2)\n",
        "        \n",
        "        sims = []\n",
        "        for n in range(3, 11):\n",
        "            attn_a = map_attn_a[n]\n",
        "            attn_b = eval(model_b, n, map_rand_input[n])\n",
        "            \n",
        "            sim = torch.mean(torch.cosine_similarity(attn_a, attn_b))\n",
        "            sims.append(sim)\n",
        "            \n",
        "        print(f\"{file2} [{model_hash(file2)}] - {torch.mean(torch.stack(sims)) * 1e2:.2f}%\")\n",
        "        \n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!wget https://huggingface.co/ckpt/anything-v3.0/resolve/main/Anything-V3.0-pruned.safetensors\n",
        "!wget https://huggingface.co/ckpt/anything-v4.0/resolve/main/anything-v4.5-pruned.safetensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python test.py \"anything-v4.5-pruned.safetensors\" \"Anything-V3.0-pruned.safetensors\""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
