{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/camenduru/notebooks/blob/main/camenduru's_sd_image_variations.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6mOBiSq8idf"
      },
      "outputs": [],
      "source": [
        "!pip install -q torch==1.13.1+cu116 torchvision==0.14.1+cu116 torchaudio==0.13.1 torchtext==0.14.1 torchdata==0.5.1 --extra-index-url https://download.pytorch.org/whl/cu116 -U\n",
        "!git clone https://huggingface.co/spaces/lambdalabs/stable-diffusion-image-variations\n",
        "%cd stable-diffusion-image-variations/\n",
        "!pip install -qq -r requirements.txt\n",
        "!pip install -qq gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fe3bzAto8uX5"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "import torch\n",
        "from PIL import Image\n",
        "\n",
        "from lambda_diffusers import StableDiffusionImageEmbedPipeline\n",
        "\n",
        "def main(\n",
        "    input_im,\n",
        "    scale=3.0,\n",
        "    n_samples=4,\n",
        "    steps=25,\n",
        "    seed=0,\n",
        "    ):\n",
        "    generator = torch.Generator(device=device).manual_seed(int(seed))\n",
        "\n",
        "    images_list = pipe(\n",
        "        n_samples*[input_im],\n",
        "        guidance_scale=scale,\n",
        "        num_inference_steps=steps,\n",
        "        generator=generator,\n",
        "        )\n",
        "\n",
        "    images = []\n",
        "    for i, image in enumerate(images_list[\"sample\"]):\n",
        "        # if(images_list[\"nsfw_content_detected\"][i]):\n",
        "        #     safe_image = Image.open(r\"unsafe.png\")\n",
        "        #     images.append(safe_image)\n",
        "        # else:\n",
        "            images.append(image)\n",
        "    return images\n",
        "\n",
        "device = \"cuda\"\n",
        "pipe = StableDiffusionImageEmbedPipeline.from_pretrained(\n",
        "    \"lambdalabs/sd-image-variations-diffusers\",\n",
        "    revision=\"273115e88df42350019ef4d628265b8c29ef4af5\",\n",
        "    )\n",
        "pipe = pipe.to(device)\n",
        "pipe.safety_checker = lambda images, clip_input: (images, False)\n",
        "\n",
        "inputs = [\n",
        "    gr.Image(),\n",
        "    gr.Slider(0, 25, value=3, step=1, label=\"Guidance scale\"),\n",
        "    gr.Slider(1, 4, value=1, step=1, label=\"Number images\"),\n",
        "    gr.Slider(5, 50, value=25, step=5, label=\"Steps\"),\n",
        "    gr.Number(0, labal=\"Seed\", precision=0)\n",
        "]\n",
        "output = gr.Gallery(label=\"Generated variations\")\n",
        "output.style(grid=2)\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=main,\n",
        "    inputs=inputs,\n",
        "    outputs=output,\n",
        "    )\n",
        "demo.launch(inline=False, debug=True)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
