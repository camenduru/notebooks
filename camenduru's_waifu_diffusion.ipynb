{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/camenduru/notebooks/blob/main/camenduru's_waifu_diffusion.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GlFhGnMdz0YY"
      },
      "outputs": [],
      "source": [
        "!pip install -q torch==1.13.1+cu116 torchvision==0.14.1+cu116 torchaudio==0.13.1 torchtext==0.14.1 torchdata==0.5.1 --extra-index-url https://download.pytorch.org/whl/cu116 -U\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "!pip install -qq git+https://github.com/huggingface/diffusers.git\n",
        "!pip install -qq transformers ftfy datasets\n",
        "\n",
        "import torch, os, gc\n",
        "from diffusers import StableDiffusionPipeline\n",
        "from torch import autocast\n",
        "from IPython.display import clear_output\n",
        "\n",
        "batch_idx = 0\n",
        "outputs_path = \"/content/gdrive/MyDrive/AI/WaifuDiffusion\"\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KF30OI0Wb91P"
      },
      "outputs": [],
      "source": [
        "is_tile = False #@param {type:'boolean'}\n",
        "if(is_tile):\n",
        "\tdef patch_conv(cls):\n",
        "\t\tinit = cls.__init__\n",
        "\t\tdef __init__(self, *args, **kwargs):\n",
        "\t\t\treturn init(self, *args, **kwargs, padding_mode='circular')\n",
        "\t\tcls.__init__ = __init__\n",
        "\tpatch_conv(torch.nn.Conv2d)\n",
        " \n",
        "pipe = StableDiffusionPipeline.from_pretrained(\"hakurei/waifu-diffusion\", revision=\"fp16\", torch_dtype=torch.float16).to(\"cuda\")\n",
        "pipe.safety_checker = lambda images, clip_input: (images, False)\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7tOGrS5lA6-D"
      },
      "outputs": [],
      "source": [
        "from PIL.PngImagePlugin import PngInfo\n",
        "metadata = PngInfo()\n",
        " \n",
        "images_path_name = \"000\" #@param {type:'string'}\n",
        "num_batch_images = 1000 \n",
        "height = 512 #@param {type:'integer'}\n",
        "width = 512 #@param {type:'integer'}\n",
        "\n",
        "path = os.path.join(outputs_path, images_path_name)\n",
        "\n",
        "if os.path.exists(path) == False:\n",
        "  os.mkdir(path)\n",
        "\n",
        "prompt = 'manga' #@param {type:'string'}\n",
        "metadata.add_text(\"Prompt\", f\"{prompt}\")\n",
        "by = 'camenduru' #@param {type:'string'}\n",
        "metadata.add_text(\"by\", f\"{by}\")\n",
        "\n",
        "for i in range(num_batch_images):\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    with autocast(\"cuda\"):\n",
        "      image = pipe(prompt, height=height, width=width, num_inference_steps=50, eta=0.0, guidance_scale=7.5)[\"sample\"][0]\n",
        "\n",
        "    image.save(f\"{path}/{images_path_name}_{batch_idx}.png\", pnginfo=metadata)\n",
        "    batch_idx += 1"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
